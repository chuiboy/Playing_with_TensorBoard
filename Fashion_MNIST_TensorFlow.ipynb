{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST  with TensorFlow & TensorBoard\n",
    "___\n",
    "In this notebook I try to get TensorBoard working on a model created using TensorFlow. TensorBoard comes with TensorFlow and useful tool for visualizing model performance. The dataset used is \"Fashion MNIST\" and was obtained from Kaggle: https://www.kaggle.com/zalando-research/fashionmnist\n",
    "___\n",
    "Reference: The material here was mostly learned from the TensorFlow Programmer's Guide on TensorBoard here: https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marvin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the dataset\n",
    "train = pd.read_csv(r'Datasets\\fashionmnist\\fashion-mnist_train.csv')\n",
    "test = pd.read_csv(r'Datasets\\fashionmnist\\fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the features and labels from the train and test set\n",
    "X_train = train.drop('label', axis=1)\n",
    "X_test = test.drop('label', axis=1)\n",
    "y_train = train['label'].values\n",
    "y_test = test['label'].values\n",
    "\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x164279b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x224e0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# An example from the dataset\n",
    "image = X_train.iloc[np.random.randint(len(X_train))].values.reshape(28,28)\n",
    "plt.imshow(image, cmap = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data and make them numpy arrays\n",
    "X_train = X_train.values / 255\n",
    "X_test = X_test.values / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_train and X_test to have the shape of the image\n",
    "X_train_image = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test_image = X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our model on TensorFlow\n",
    "___\n",
    "Build our model using tf.name_scope to organize the model graph, and tf.summary to display the graph, scalars, histograms, distributions and images on TensorBoard. Note that when predicting accuracy on the test set I only use 1000 examples because of lack of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that creates mini-batches\n",
    "def mini_batch(X, y, batch_size):\n",
    "    batches = []\n",
    "    batch_count = int(X.shape[0] / batch_size)\n",
    "    \n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    X_shuffled = X[permutation, :]\n",
    "    y_shuffled = y[permutation]\n",
    "    \n",
    "    for i in range(batch_count):\n",
    "        x_batch = X_shuffled[i*batch_size:i*batch_size+batch_size, :]\n",
    "        y_batch = y_shuffled[i*batch_size:i*batch_size+batch_size]\n",
    "        batch = [x_batch, y_batch]\n",
    "        batches.append(batch)\n",
    "    \n",
    "    if (X.shape[0] % batch_size) != 0:\n",
    "        x_batch = X_shuffled[batch_count*batch_size:, :]\n",
    "        y_batch = y_shuffled[batch_count*batch_size:]\n",
    "        batch = [x_batch, y_batch]\n",
    "        batches.append(batch)\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter initialization functions\n",
    "def weight_variable(shape):\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    return tf.Variable(initializer(shape), name='W')\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.zeros(shape), name='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a convolutional layer\n",
    "def conv_layer(input, size_in, size_out, name='conv'):\n",
    "    with tf.name_scope(name):\n",
    "        W = weight_variable([3, 3, size_in, size_out])\n",
    "        b = bias_variable([size_out])\n",
    "        Z = tf.nn.conv2d(input, W, strides=[1, 1, 1, 1], padding='VALID') + b\n",
    "        A = tf.nn.relu(Z, name='A')\n",
    "        \n",
    "        # Parameters and activations show up in the TensorBoard histogram\n",
    "        tf.summary.histogram('weights', W)\n",
    "        tf.summary.histogram('biases', b)\n",
    "        tf.summary.histogram('activations', A)        \n",
    "        return A\n",
    "\n",
    "# Define a max-pooling layer\n",
    "def max_pool(input, name='maxpool'):\n",
    "    with tf.name_scope(name):\n",
    "        out = tf.nn.max_pool(input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')        \n",
    "        return out\n",
    "\n",
    "# Define a fully-connected layer\n",
    "def fc_layer(input, size_in, size_out, name='fc', act=None):\n",
    "    with tf.name_scope(name):\n",
    "        W = weight_variable([size_in, size_out])\n",
    "        b = bias_variable([size_out])\n",
    "        Z = tf.matmul(input, W) + b\n",
    "        if act == 'relu':\n",
    "            A = tf.nn.relu(Z, name='A')\n",
    "        else:\n",
    "            A = Z\n",
    "        \n",
    "        # Parameters and activations show up in the TensorBoard histogram\n",
    "        tf.summary.histogram('weights', W)\n",
    "        tf.summary.histogram('biases', b)\n",
    "        tf.summary.histogram('activations', A)       \n",
    "        return A\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the logging directory\n",
    "LOGDIR = r'C:\\Users\\Marvin\\Desktop\\MachineLearning\\Code\\logs\\FashionMNIST_tf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy at step 0: 0.038\n",
      "Test accuracy at step 10: 0.655\n",
      "Test accuracy at step 20: 0.682\n",
      "Test accuracy at step 30: 0.741\n",
      "Test accuracy at step 40: 0.766\n",
      "Test accuracy at step 50: 0.749\n",
      "Test accuracy at step 60: 0.787\n",
      "Test accuracy at step 70: 0.787\n",
      "Test accuracy at step 80: 0.793\n",
      "Test accuracy at step 90: 0.794\n",
      "Test accuracy at step 100: 0.802\n",
      "Test accuracy at step 110: 0.807\n",
      "Test accuracy at step 120: 0.818\n",
      "Test accuracy at step 130: 0.82\n",
      "Test accuracy at step 140: 0.823\n",
      "Test accuracy at step 150: 0.834\n",
      "Test accuracy at step 160: 0.809\n",
      "Test accuracy at step 170: 0.838\n",
      "Test accuracy at step 180: 0.848\n",
      "Test accuracy at step 190: 0.839\n",
      "Test accuracy at step 200: 0.848\n",
      "Test accuracy at step 210: 0.842\n",
      "Test accuracy at step 220: 0.867\n",
      "Test accuracy at step 230: 0.841\n",
      "Test accuracy at step 240: 0.866\n",
      "Test accuracy at step 250: 0.864\n",
      "Test accuracy at step 260: 0.874\n",
      "Test accuracy at step 270: 0.863\n",
      "Test accuracy at step 280: 0.876\n",
      "Test accuracy at step 290: 0.856\n",
      "Test accuracy at step 300: 0.875\n",
      "Test accuracy at step 310: 0.883\n",
      "Test accuracy at step 320: 0.859\n",
      "Test accuracy at step 330: 0.888\n",
      "Test accuracy at step 340: 0.89\n",
      "Test accuracy at step 350: 0.869\n",
      "Test accuracy at step 360: 0.873\n",
      "Test accuracy at step 370: 0.877\n",
      "Test accuracy at step 380: 0.882\n",
      "Test accuracy at step 390: 0.887\n",
      "Test accuracy at step 400: 0.891\n",
      "Test accuracy at step 410: 0.864\n",
      "Test accuracy at step 420: 0.888\n",
      "Test accuracy at step 430: 0.891\n",
      "Test accuracy at step 440: 0.9\n",
      "Test accuracy at step 450: 0.893\n",
      "Test accuracy at step 460: 0.882\n",
      "Test accuracy at step 470: 0.884\n",
      "Test accuracy at step 480: 0.873\n",
      "Test accuracy at step 490: 0.885\n",
      "Test accuracy at step 500: 0.895\n",
      "Test accuracy at step 510: 0.881\n",
      "Test accuracy at step 520: 0.869\n",
      "Test accuracy at step 530: 0.893\n",
      "Test accuracy at step 540: 0.894\n",
      "Test accuracy at step 550: 0.899\n",
      "Test accuracy at step 560: 0.895\n",
      "Test accuracy at step 570: 0.904\n",
      "Test accuracy at step 580: 0.902\n",
      "Test accuracy at step 590: 0.903\n",
      "Test accuracy at step 600: 0.899\n",
      "Test accuracy at step 610: 0.888\n",
      "Test accuracy at step 620: 0.897\n",
      "Test accuracy at step 630: 0.899\n",
      "Test accuracy at step 640: 0.907\n",
      "Test accuracy at step 650: 0.902\n",
      "Test accuracy at step 660: 0.895\n",
      "Test accuracy at step 670: 0.883\n",
      "Test accuracy at step 680: 0.905\n",
      "Test accuracy at step 690: 0.896\n",
      "Test accuracy at step 700: 0.897\n",
      "Test accuracy at step 710: 0.907\n",
      "Test accuracy at step 720: 0.91\n",
      "Test accuracy at step 730: 0.905\n",
      "Test accuracy at step 740: 0.906\n",
      "Test accuracy at step 750: 0.889\n",
      "Test accuracy at step 760: 0.898\n",
      "Test accuracy at step 770: 0.892\n",
      "Test accuracy at step 780: 0.89\n",
      "Test accuracy at step 790: 0.917\n",
      "Test accuracy at step 800: 0.913\n",
      "Test accuracy at step 810: 0.908\n",
      "Test accuracy at step 820: 0.916\n",
      "Test accuracy at step 830: 0.905\n",
      "Test accuracy at step 840: 0.914\n",
      "Test accuracy at step 850: 0.908\n",
      "Test accuracy at step 860: 0.913\n",
      "Test accuracy at step 870: 0.902\n",
      "Test accuracy at step 880: 0.914\n",
      "Test accuracy at step 890: 0.923\n",
      "Test accuracy at step 900: 0.914\n",
      "Test accuracy at step 910: 0.904\n",
      "Test accuracy at step 920: 0.899\n",
      "Test accuracy at step 930: 0.914\n",
      "Test accuracy at step 940: 0.909\n",
      "Test accuracy at step 950: 0.91\n",
      "Test accuracy at step 960: 0.911\n",
      "Test accuracy at step 970: 0.9\n",
      "Test accuracy at step 980: 0.914\n",
      "Test accuracy at step 990: 0.896\n",
      "Test accuracy at step 1000: 0.91\n",
      "Test accuracy at step 1010: 0.906\n",
      "Test accuracy at step 1020: 0.908\n",
      "Test accuracy at step 1030: 0.905\n",
      "Test accuracy at step 1040: 0.898\n",
      "Test accuracy at step 1050: 0.913\n",
      "Test accuracy at step 1060: 0.906\n",
      "Test accuracy at step 1070: 0.916\n",
      "Test accuracy at step 1080: 0.901\n",
      "Test accuracy at step 1090: 0.91\n",
      "Test accuracy at step 1100: 0.91\n",
      "Test accuracy at step 1110: 0.91\n",
      "Test accuracy at step 1120: 0.919\n",
      "Test accuracy at step 1130: 0.914\n",
      "Test accuracy at step 1140: 0.924\n",
      "Test accuracy at step 1150: 0.918\n",
      "Test accuracy at step 1160: 0.909\n",
      "Test accuracy at step 1170: 0.922\n",
      "Test accuracy at step 1180: 0.907\n",
      "Test accuracy at step 1190: 0.909\n",
      "Test accuracy at step 1200: 0.898\n",
      "Test accuracy at step 1210: 0.92\n",
      "Test accuracy at step 1220: 0.913\n",
      "Test accuracy at step 1230: 0.918\n",
      "Test accuracy at step 1240: 0.915\n",
      "Test accuracy at step 1250: 0.904\n",
      "Test accuracy at step 1260: 0.922\n",
      "Test accuracy at step 1270: 0.917\n",
      "Test accuracy at step 1280: 0.911\n",
      "Test accuracy at step 1290: 0.917\n",
      "Test accuracy at step 1300: 0.93\n",
      "Test accuracy at step 1310: 0.924\n",
      "Test accuracy at step 1320: 0.929\n",
      "Test accuracy at step 1330: 0.92\n",
      "Test accuracy at step 1340: 0.929\n",
      "Test accuracy at step 1350: 0.9\n",
      "Test accuracy at step 1360: 0.92\n",
      "Test accuracy at step 1370: 0.916\n",
      "Test accuracy at step 1380: 0.926\n",
      "Test accuracy at step 1390: 0.922\n",
      "Test accuracy at step 1400: 0.905\n"
     ]
    }
   ],
   "source": [
    "### Building and training the ConvNet\n",
    "\n",
    "# Reset graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholders\n",
    "X = tf.placeholder(tf.float32, [None, 784], name='X')\n",
    "X_image = tf.reshape(X, [-1, 28, 28, 1])\n",
    "y = tf.placeholder(tf.int64, [None], name='y')\n",
    "\n",
    "# summary to display images in TensorBoard\n",
    "tf.summary.image('input', X_image)\n",
    "\n",
    "# Model\n",
    "conv1 = conv_layer(X_image, 1, 32, 'conv1')\n",
    "conv2 = conv_layer(conv1, 32, 64, 'conv2')\n",
    "maxpool2 = max_pool(conv2, 'maxpool2')\n",
    "conv3 = conv_layer(maxpool2, 64, 128, 'conv3')\n",
    "conv4 = conv_layer(conv3, 128, 128, 'conv4')\n",
    "maxpool4 = max_pool(conv4, 'maxpool4')\n",
    "flatten = tf.reshape(maxpool4, [-1, 4 * 4 * 128], 'flatten')\n",
    "fc5 = fc_layer(flatten, 4 * 4 * 128, 1024, 'fc5', 'relu')\n",
    "logits = fc_layer(fc5, 1024, 10, 'fc6')\n",
    "\n",
    "\n",
    "# Cross-entropy\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    xent = tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=y)\n",
    "    tf.summary.scalar('cross_entropy', xent) # summary to display cross-entropy\n",
    "\n",
    "# Training step\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(1e-3).minimize(xent)\n",
    "\n",
    "# Accuracy\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy) # summary to display accuracy\n",
    "\n",
    "# Merge all summaries\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "# Create FileWriters to write in summaries and model graph\n",
    "train_writer = tf.summary.FileWriter(LOGDIR + r'\\train')\n",
    "test_writer = tf.summary.FileWriter(LOGDIR + r'\\test')\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Write in the graph\n",
    "    train_writer.add_graph(sess.graph)\n",
    "    \n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training\n",
    "    step = 0\n",
    "    for i in range(3): # num epochs\n",
    "        batches = mini_batch(X=X_train, y=y_train, batch_size=128)\n",
    "        \n",
    "        for batch in batches:    \n",
    "            if step % 10 == 0: # Record summaries and print test set accuracy\n",
    "                summary, acc = sess.run([merged, accuracy], feed_dict={X: X_test[:1000,:], y: y_test[:1000]})\n",
    "                test_writer.add_summary(summary, step)\n",
    "                print('Test accuracy at step %s: %s' % (step, acc))\n",
    "            else:\n",
    "                summary, _ = sess.run([merged, train_step], feed_dict={X: batch[0], y: batch[1]})\n",
    "                train_writer.add_summary(summary, step)\n",
    "            \n",
    "            step += 1\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just open up a command prompt and type: Tensorboard --logdir *\"Insert your LOGDIR here\"*\n",
    "\n",
    "And open the address that's returned in a new tab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
